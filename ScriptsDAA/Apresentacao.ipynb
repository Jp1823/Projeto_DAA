{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dados e Aprendizagem Automática  \n",
    "### Introdução\n",
    "\n",
    "## SVM using GenAudio Dataset  \n",
    "\n",
    "For this class, we will use a music dataset. The [GenAudio dataset](#) is composed by audio files and CSV files with extracted features from the audio files:\n",
    "\n",
    "- **genres original** - collection of 10 genres with 100 audio files each, all having a length of 30 seconds.\n",
    "- **CSV files** - extracted features of the audio files. One file has for each song (30 seconds long) a mean and variance computed over multiple features that can be extracted from an audio file. The other file has the same structure, but the songs were split before into 3 seconds audio files (this way increasing 10 times the amount of data we fuel into our classification models).\n",
    "\n",
    "This dataset is frequently used for evaluation in machine listening research for Music Genre Recognition (MGR). The files were collected in 2000–2001 from a variety of sources including personal CDs, radio, microphone recordings, in order to represent a variety of recording.\n",
    "\n",
    "---\n",
    "\n",
    "### Imports, installations and settings\n",
    "\n",
    "In order to work with audio data, we will use **librosa**, a Python library used for audio and music analysis. It is a powerful package widely used for audio visualization and for building Music Information Retrieval (MIR) systems.\n",
    "\n",
    "Install librosa:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hipp_train = pd.read_csv('train_radiomics_hipocamp.csv')\n",
    "hipp_test = pd.read_csv('test_radiomics_hipocamp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover colunas com apenas um valor e colunas irrelevantes\n",
    "colunas_remover = ['Image', 'diagnostics_Image-original_Hash', 'diagnostics_Mask-original_Hash',\n",
    "                   'diagnostics_Mask-original_BoundingBox', 'diagnostics_Mask-original_CenterOfMassIndex',\n",
    "                   'diagnostics_Mask-original_CenterOfMass', 'Mask']\n",
    "hipp_train_c = hipp_train.drop(columns=colunas_remover, errors='ignore').loc[:, hipp_train.nunique() > 1]\n",
    "hipp_test_c = hipp_test.drop(columns=colunas_remover, errors='ignore').loc[:, hipp_test.nunique() > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear a coluna 'Transition' para valores numéricos\n",
    "mapping = {\n",
    "    'CN-CN': 0,  # Estado Normal\n",
    "    'CN-MCI': 1,  # Estado Intermediário\n",
    "    'MCI-MCI': 2,  # Estado Intermediário\n",
    "    'MCI-AD': 3,  # Demência\n",
    "    'AD-AD': 4    # Demência\n",
    "}\n",
    "hipp_train_c['Transition'] = hipp_train_c['Transition'].map(mapping)\n",
    "\n",
    "# Remover qualquer entrada com valores nulos na coluna 'Transition' após o mapeamento\n",
    "hipp_train_c.dropna(subset=['Transition'], inplace=True)\n",
    "\n",
    "# Preparar dados para treinamento\n",
    "X_train = hipp_train_c.drop(['Transition', 'ID'], axis=1, errors='ignore')\n",
    "y_train = hipp_train_c['Transition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train, y_train, test_size=0.2, random_state=2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "pg_model = RandomForestClassifier(bootstrap=True, max_depth=20, random_state=2022)\n",
    "# pg_model = XGBClassifier(max_depth=20, random_state=2022)\n",
    "# pg_model = make_pipeline(StandardScaler(), SVC(kernel='rbf', C=1.0, gamma='scale', random_state=2021))\n",
    "\n",
    "# Train the model\n",
    "pg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = pg_model.predict(X_test_split)\n",
    "\n",
    "\n",
    "pg_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Fazer previsões no conjunto de teste\n",
    "predictions = pg_model.predict(X_test_split)\n",
    "\n",
    "# Exibir o classification report\n",
    "print(classification_report(y_test_split, predictions, target_names=list(mapping.keys())))\n",
    "\n",
    "# Fazer previsões no conjunto de teste final\n",
    "X_test = hipp_test_c.drop(columns=['ID'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicionário inverso para mapear de volta para os rótulos originais\n",
    "inverse_mapping = {1: 'CN-CN', 2: 'CN-MCI', 3: 'MCI-MCI', 4: 'MCI-AD', 5: 'AD-AD'}\n",
    "predictions_mapped = pd.Series(pg_model.predict(X_test)).map(inverse_mapping)\n",
    "\n",
    "# Criar o DataFrame para a submissão\n",
    "submission_df = pd.DataFrame({\n",
    "    'RowId': range(1, len(predictions_mapped) + 1), \n",
    "    'Result': predictions_mapped\n",
    "})\n",
    "\n",
    "\n",
    "if len(submission_df) < 100:\n",
    "    print(\"Aviso: O conjunto de teste contém menos de 100 entradas. Submissão terá apenas\", len(submission_df), \"previsões.\")\n",
    "else:\n",
    "    print(\"Número total de previsões:\", len(submission_df))\n",
    "\n",
    "# Guardar as alterações num ficheiro\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submissão salva com sucesso com exatamente\", len(submission_df), \"previsões.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envName",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
